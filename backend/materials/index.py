"""API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —É—á–µ–±–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ presigned URL"""

import json
import os
import boto3
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
import jwt
from openai import OpenAI
import io
from PyPDF2 import PdfReader
from docx import Document

MAX_FILE_SIZE = 50 * 1024 * 1024
CHUNK_SIZE = 4000


def get_db_connection():
    dsn = os.environ['DATABASE_URL']
    schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
    return psycopg2.connect(dsn, options=f'-c search_path={schema}')


def verify_token(token: str) -> dict:
    secret = os.environ['JWT_SECRET']
    try:
        return jwt.decode(token, secret, algorithms=['HS256'])
    except:
        return None


def check_subscription_access(conn, user_id: int) -> dict:
    schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    cursor.execute(f'''
        SELECT subscription_type, subscription_expires_at, trial_ends_at, is_trial_used 
        FROM {schema}.users 
        WHERE id = %s
    ''', (user_id,))
    user = cursor.fetchone()
    cursor.close()
    
    if not user:
        return {'has_access': False, 'reason': 'user_not_found'}
    
    now = datetime.now()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫—É
    if user.get('subscription_type') == 'premium':
        if user.get('subscription_expires_at') and user['subscription_expires_at'].replace(tzinfo=None) > now:
            return {'has_access': True, 'is_premium': True, 'is_trial': False}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∏–∞–ª –ø–µ—Ä–∏–æ–¥
    trial_ends = user.get('trial_ends_at')
    is_trial_used = user.get('is_trial_used')
    
    if trial_ends and not is_trial_used:
        trial_ends_naive = trial_ends.replace(tzinfo=None) if trial_ends.tzinfo else trial_ends
        if trial_ends_naive > now:
            return {'has_access': True, 'is_premium': False, 'is_trial': True, 'trial_ends_at': trial_ends}
    
    return {'has_access': False, 'reason': 'no_subscription'}


def get_s3_client():
    return boto3.client('s3',
        endpoint_url='https://bucket.poehali.dev',
        aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
        aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'])


def generate_presigned_upload_url(filename: str, file_type: str, user_id: int) -> dict:
    s3 = get_s3_client()
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    key = f"materials/{user_id}_{timestamp}_{filename}"
    
    try:
        presigned_url = s3.generate_presigned_url('put_object',
            Params={'Bucket': 'files', 'Key': key, 'ContentType': file_type},
            ExpiresIn=3600)
        
        cdn_url = f"https://cdn.poehali.dev/projects/{os.environ['AWS_ACCESS_KEY_ID']}/bucket/{key}"
        return {'upload_url': presigned_url, 'file_key': key, 'cdn_url': cdn_url}
    except Exception as e:
        print(f"[MATERIALS] –û—à–∏–±–∫–∞ presigned URL: {e}")
        return None


def download_file_from_s3(file_key: str) -> bytes:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ S3 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –±—ç–∫–µ–Ω–¥–µ"""
    s3 = get_s3_client()
    try:
        print(f"[MATERIALS] –°–∫–∞—á–∏–≤–∞—é –∏–∑ S3: Bucket=files, Key={file_key}")
        response = s3.get_object(Bucket='files', Key=file_key)
        data = response['Body'].read()
        print(f"[MATERIALS] –°–∫–∞—á–∞–Ω–æ {len(data)} –±–∞–π—Ç")
        return data
    except Exception as e:
        print(f"[MATERIALS] –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ S3: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_text_from_pdf(file_data: bytes) -> str:
    try:
        pdf_reader = PdfReader(io.BytesIO(file_data))
        return '\n\n'.join([page.extract_text() for page in pdf_reader.pages])
    except Exception as e:
        print(f"[MATERIALS] PDF –æ—à–∏–±–∫–∞: {e}")
        return ""


def extract_text_from_docx(file_data: bytes) -> str:
    try:
        doc = Document(io.BytesIO(file_data))
        return '\n\n'.join([p.text for p in doc.paragraphs if p.text.strip()])
    except Exception as e:
        print(f"[MATERIALS] DOCX –æ—à–∏–±–∫–∞: {e}")
        return ""


def extract_text_from_txt(file_data: bytes) -> str:
    for encoding in ['utf-8', 'windows-1251', 'cp1251', 'latin-1']:
        try:
            return file_data.decode(encoding)
        except:
            continue
    return file_data.decode('utf-8', errors='ignore')


def extract_text_from_file(file_data: bytes, file_type: str) -> str:
    if 'pdf' in file_type.lower():
        return extract_text_from_pdf(file_data)
    elif 'word' in file_type.lower() or 'document' in file_type.lower():
        return extract_text_from_docx(file_data)
    elif 'text' in file_type.lower() or 'plain' in file_type.lower():
        return extract_text_from_txt(file_data)
    return ""


def split_text_into_chunks(text: str) -> list:
    if not text:
        return []
    paragraphs = text.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) + 2 <= CHUNK_SIZE:
            current_chunk += para + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


def analyze_document_with_deepseek(full_text: str, filename: str) -> dict:
    deepseek_key = os.environ.get('DEEPSEEK_API_KEY')
    
    if not deepseek_key or not full_text or len(full_text) < 10:
        return {'summary': '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω', 'subject': '–û–±—â–µ–µ', 'title': filename[:50], 'tasks': []}
    
    print(f"[MATERIALS] DeepSeek –∞–Ω–∞–ª–∏–∑ –Ω–∞—á–∞—Ç, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞={len(full_text)}")
    
    try:
        client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com", timeout=30.0)
        text_preview = full_text[:3000]
        
        prompt = f"""–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ —Å—Ç—É–¥–µ–Ω—Ç–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç "{filename}".

–ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞:
{text_preview}

–í–µ—Ä–Ω–∏ JSON:
{{"summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)", "subject": "–ü—Ä–µ–¥–º–µ—Ç", "title": "–ù–∞–∑–≤–∞–Ω–∏–µ (–º–∞–∫—Å 50 —Å–∏–º–≤–æ–ª–æ–≤)", "tasks": [{{"title": "–ó–∞–¥–∞—á–∞", "deadline": "YYYY-MM-DD –∏–ª–∏ null"}}]}}"""
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            response_format={"type": "json_object"})
        
        content = response.choices[0].message.content
        if '```json' in content:
            content = content.split('```json')[1].split('```')[0].strip()
        elif '```' in content:
            content = content.split('```')[1].split('```')[0].strip()
        
        result = json.loads(content)
        print(f"[MATERIALS] DeepSeek –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: title={result.get('title')}, subject={result.get('subject')}")
        return result
    except Exception as e:
        print(f"[MATERIALS] Deepseek –æ—à–∏–±–∫–∞: {e}")
        return {'summary': '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω (–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)', 'subject': '–û–±—â–µ–µ', 'title': filename[:50], 'tasks': []}


def handler(event: dict, context) -> dict:
    method = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {'statusCode': 200, 'headers': {'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Content-Type, Authorization, X-Authorization'}, 'body': ''}
    
    headers = {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'}
    auth_header = event.get('headers', {}).get('X-Authorization', '')
    token = auth_header.replace('Bearer ', '')
    
    if not token:
        return {'statusCode': 401, 'headers': headers, 'body': json.dumps({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è'})}
    
    payload = verify_token(token)
    if not payload:
        return {'statusCode': 401, 'headers': headers, 'body': json.dumps({'error': '–ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω'})}
    
    user_id = payload['user_id']
    
    # POST - –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
    if method == 'POST':
        body = json.loads(event.get('body', '{}'))
        action = body.get('action')
        
        # –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ base64 (–æ–±—Ö–æ–¥ CORS –ø—Ä–æ–±–ª–µ–º)
        if action == 'upload_direct':
            try:
                conn = get_db_connection()
                access = check_subscription_access(conn, user_id)
                conn.close()
                
                if not access['has_access']:
                    message = '‚è∞ –ü–æ–¥–ø–∏—Å–∫–∞ –∏—Å—Ç–µ–∫–ª–∞' if access.get('reason') == 'subscription_expired' else 'üîí –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–ø–∏—Å–∫–∞'
                    return {'statusCode': 403, 'headers': headers, 'body': json.dumps({'error': 'subscription_required', 'message': message})}
                
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_data_base64 = body.get('fileData')
                
                if not filename or not file_type or not file_data_base64:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã filename, fileType –∏–ª–∏ fileData'})}
                
                import base64
                file_data = base64.b64decode(file_data_base64)
                file_size = len(file_data)
                
                if file_size > MAX_FILE_SIZE:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': f'–ú–∞–∫—Å —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // 1024 // 1024} –ú–ë'})}
                
                print(f"[MATERIALS] –ó–∞–≥—Ä—É–∑–∫–∞ {filename}, —Ä–∞–∑–º–µ—Ä={file_size} –±–∞–π—Ç")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
                s3 = get_s3_client()
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                import random
                file_key = f"materials/{user_id}_{timestamp}_{random.randint(10000000, 99999999)}_{filename}"
                
                s3.put_object(Bucket='files', Key=file_key, Body=file_data, ContentType=file_type)
                cdn_url = f"https://cdn.poehali.dev/projects/{os.environ['AWS_ACCESS_KEY_ID']}/bucket/{file_key}"
                
                print(f"[MATERIALS] –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ S3: {file_key}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
                print(f"[MATERIALS] –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç, —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
                full_text = extract_text_from_file(file_data, file_type)
                
                if not full_text or len(full_text.strip()) < 10:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                chunks = split_text_into_chunks(full_text)
                analysis = analyze_document_with_deepseek(full_text, filename)
                
                title = (analysis.get('title') or filename)[:200]
                subject = (analysis.get('subject') or '–û–±—â–µ–µ')[:100]
                summary = (analysis.get('summary') or '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω')[:2000]
                
                conn = get_db_connection()
                try:
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        cur.execute("""
                            INSERT INTO materials (user_id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            RETURNING id, title, subject, file_url, summary, file_type, file_size, total_chunks, created_at
                        """, (user_id, title, subject, cdn_url, full_text[:10000], summary, file_type, file_size, len(chunks)))
                        
                        material = cur.fetchone()
                        material_id = material['id']
                        
                        for idx, chunk in enumerate(chunks):
                            cur.execute("INSERT INTO document_chunks (material_id, chunk_index, chunk_text) VALUES (%s, %s, %s)", (material_id, idx, chunk))
                        
                        conn.commit()
                        print(f"[MATERIALS] –ú–∞—Ç–µ—Ä–∏–∞–ª —Å–æ–∑–¥–∞–Ω: ID={material_id}, {len(chunks)} —á–∞–Ω–∫–æ–≤")
                        
                        return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'material': dict(material), 'chunks_created': len(chunks)})}
                finally:
                    conn.close()
            except Exception as e:
                print(f"[MATERIALS] –û—à–∏–±–∫–∞ upload_direct: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        # –®–∞–≥ 1: –ø–æ–ª—É—á–∏—Ç—å presigned URL (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥, –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        elif action == 'get_upload_url':
            try:
                conn = get_db_connection()
                access = check_subscription_access(conn, user_id)
                conn.close()
                
                if not access['has_access']:
                    message = '‚è∞ –ü–æ–¥–ø–∏—Å–∫–∞ –∏—Å—Ç–µ–∫–ª–∞' if access.get('reason') == 'subscription_expired' else 'üîí –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–ø–∏—Å–∫–∞'
                    return {'statusCode': 403, 'headers': headers, 'body': json.dumps({'error': 'subscription_required', 'message': message})}
                
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_size = body.get('fileSize', 0)
                
                if not filename or not file_type:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã filename –∏ fileType'})}
                
                if file_size > MAX_FILE_SIZE:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': f'–ú–∞–∫—Å —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // 1024 // 1024} –ú–ë'})}
                
                presigned_data = generate_presigned_upload_url(filename, file_type, user_id)
                if not presigned_data:
                    return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ URL'})}
                
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps(presigned_data)}
            except Exception as e:
                print(f"[MATERIALS] –û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        # –®–∞–≥ 2: –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        elif action == 'process_file':
            try:
                file_key = body.get('fileKey')
                cdn_url = body.get('cdnUrl')
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_size = body.get('fileSize')
                
                if not file_key or not cdn_url:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã fileKey/cdnUrl'})}
                
                print(f"[MATERIALS] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}, key={file_key}")
                file_data = download_file_from_s3(file_key)
                
                if not file_data:
                    return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç, —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
                full_text = extract_text_from_file(file_data, file_type)
                
                if not full_text or len(full_text.strip()) < 10:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                chunks = split_text_into_chunks(full_text)
                analysis = analyze_document_with_deepseek(full_text, filename)
                
                title = (analysis.get('title') or filename)[:200]
                subject = (analysis.get('subject') or '–û–±—â–µ–µ')[:100]
                summary = (analysis.get('summary') or '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω')[:2000]
                
                conn = get_db_connection()
                try:
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        cur.execute("""
                            INSERT INTO materials (user_id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            RETURNING id, title, subject, file_url, summary, file_type, file_size, total_chunks, created_at
                        """, (user_id, title, subject, cdn_url, full_text[:10000], summary, file_type, file_size, len(chunks)))
                        
                        material = cur.fetchone()
                        material_id = material['id']
                        
                        for idx, chunk in enumerate(chunks):
                            cur.execute("INSERT INTO document_chunks (material_id, chunk_index, chunk_text) VALUES (%s, %s, %s)", (material_id, idx, chunk))
                        
                        conn.commit()
                        print(f"[MATERIALS] –°–æ–∑–¥–∞–Ω: ID={material_id}")
                        return {'statusCode': 201, 'headers': headers, 'body': json.dumps({'material': dict(material), 'tasks': analysis.get('tasks', []), 'chunks_count': len(chunks)}, default=str)}
                finally:
                    conn.close()
            except Exception as e:
                print(f"[MATERIALS] –û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ'})}
    
    # GET - —Å–ø–∏—Å–æ–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
    elif method == 'GET':
        conn = get_db_connection()
        try:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("SELECT id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks, created_at FROM materials WHERE user_id = %s ORDER BY created_at DESC", (user_id,))
                materials = cur.fetchall()
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'materials': [dict(m) for m in materials]}, default=str)}
        finally:
            conn.close()
    
    # DELETE - —É–¥–∞–ª–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª
    elif method == 'DELETE':
        material_id = event.get('queryStringParameters', {}).get('id')
        if not material_id:
            return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': 'ID –Ω–µ —É–∫–∞–∑–∞–Ω'})}
        
        conn = get_db_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("DELETE FROM document_chunks WHERE material_id IN (SELECT id FROM materials WHERE id = %s AND user_id = %s)", (material_id, user_id))
                cur.execute("DELETE FROM materials WHERE id = %s AND user_id = %s", (material_id, user_id))
                conn.commit()
                
                if cur.rowcount == 0:
                    return {'statusCode': 404, 'headers': headers, 'body': json.dumps({'error': '–ù–µ –Ω–∞–π–¥–µ–Ω'})}
                
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'message': '–£–¥–∞–ª—ë–Ω'})}
        finally:
            conn.close()
    
    return {'statusCode': 405, 'headers': headers, 'body': json.dumps({'error': '–ú–µ—Ç–æ–¥ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è'})}