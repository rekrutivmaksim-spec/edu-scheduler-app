"""API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —É—á–µ–±–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ presigned URL"""

import json
import os
import hashlib
import boto3
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
import jwt
from openai import OpenAI
import io
from PyPDF2 import PdfReader
from docx import Document
from rate_limiter import check_rate_limit, get_client_ip
from security_validator import sanitize_filename, check_ownership

MAX_FILE_SIZE = 50 * 1024 * 1024
CHUNK_SIZE = 3500
CHUNK_OVERLAP = 500  # Overlap –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏


def get_db_connection():
    dsn = os.environ['DATABASE_URL']
    schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
    return psycopg2.connect(dsn, options=f'-c search_path={schema}')


def verify_token(token: str) -> dict:
    secret = os.environ['JWT_SECRET']
    try:
        return jwt.decode(token, secret, algorithms=['HS256'])
    except:
        return None


def check_subscription_access(conn, user_id: int) -> dict:
    schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    cursor.execute(f'''
        SELECT subscription_type, subscription_expires_at, trial_ends_at, is_trial_used 
        FROM {schema}.users 
        WHERE id = %s
    ''', (user_id,))
    user = cursor.fetchone()
    cursor.close()
    
    if not user:
        return {'has_access': False, 'reason': 'user_not_found'}
    
    now = datetime.now()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫—É
    if user.get('subscription_type') == 'premium':
        if user.get('subscription_expires_at') and user['subscription_expires_at'].replace(tzinfo=None) > now:
            return {'has_access': True, 'is_premium': True, 'is_trial': False}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∏–∞–ª –ø–µ—Ä–∏–æ–¥
    trial_ends = user.get('trial_ends_at')
    is_trial_used = user.get('is_trial_used')
    
    if trial_ends and not is_trial_used:
        trial_ends_naive = trial_ends.replace(tzinfo=None) if trial_ends.tzinfo else trial_ends
        if trial_ends_naive > now:
            return {'has_access': True, 'is_premium': False, 'is_trial': True, 'trial_ends_at': trial_ends}
    
    return {'has_access': False, 'reason': 'no_subscription'}


def get_s3_client():
    return boto3.client('s3',
        endpoint_url='https://bucket.poehali.dev',
        aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],
        aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'])


def generate_presigned_upload_url(filename: str, file_type: str, user_id: int) -> dict:
    s3 = get_s3_client()
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    key = f"materials/{user_id}_{timestamp}_{filename}"
    
    try:
        presigned_url = s3.generate_presigned_url('put_object',
            Params={'Bucket': 'files', 'Key': key, 'ContentType': file_type},
            ExpiresIn=3600)
        
        cdn_url = f"https://cdn.poehali.dev/projects/{os.environ['AWS_ACCESS_KEY_ID']}/bucket/{key}"
        return {'upload_url': presigned_url, 'file_key': key, 'cdn_url': cdn_url}
    except Exception as e:
        print(f"[MATERIALS] –û—à–∏–±–∫–∞ presigned URL: {e}")
        return None


def download_file_from_s3(file_key: str) -> bytes:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ S3 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –±—ç–∫–µ–Ω–¥–µ"""
    s3 = get_s3_client()
    try:
        print(f"[MATERIALS] –°–∫–∞—á–∏–≤–∞—é –∏–∑ S3: Bucket=files, Key={file_key}")
        response = s3.get_object(Bucket='files', Key=file_key)
        data = response['Body'].read()
        print(f"[MATERIALS] –°–∫–∞—á–∞–Ω–æ {len(data)} –±–∞–π—Ç")
        return data
    except Exception as e:
        print(f"[MATERIALS] –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ S3: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_text_from_pdf(file_data: bytes) -> str:
    try:
        pdf_reader = PdfReader(io.BytesIO(file_data))
        return '\n\n'.join([page.extract_text() for page in pdf_reader.pages])
    except Exception as e:
        print(f"[MATERIALS] PDF –æ—à–∏–±–∫–∞: {e}")
        return ""


def extract_text_from_docx(file_data: bytes) -> str:
    try:
        doc = Document(io.BytesIO(file_data))
        text_parts = []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        for p in doc.paragraphs:
            if p.text.strip():
                text_parts.append(p.text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
        for table in doc.tables:
            table_text = []
            for row in table.rows:
                row_text = ' | '.join([cell.text.strip() for cell in row.cells if cell.text.strip()])
                if row_text:
                    table_text.append(row_text)
            if table_text:
                text_parts.append('\n[–¢–ê–ë–õ–ò–¶–ê]\n' + '\n'.join(table_text) + '\n[/–¢–ê–ë–õ–ò–¶–ê]\n')
        
        return '\n\n'.join(text_parts)
    except Exception as e:
        print(f"[MATERIALS] DOCX –æ—à–∏–±–∫–∞: {e}")
        return ""


def extract_text_from_txt(file_data: bytes) -> str:
    for encoding in ['utf-8', 'windows-1251', 'cp1251', 'latin-1']:
        try:
            return file_data.decode(encoding)
        except:
            continue
    return file_data.decode('utf-8', errors='ignore')


def extract_text_from_file(file_data: bytes, file_type: str) -> str:
    if 'pdf' in file_type.lower():
        return extract_text_from_pdf(file_data)
    elif 'word' in file_type.lower() or 'document' in file_type.lower():
        return extract_text_from_docx(file_data)
    elif 'text' in file_type.lower() or 'plain' in file_type.lower():
        return extract_text_from_txt(file_data)
    return ""


def split_text_into_chunks(text: str) -> list:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å overlap –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return []
    paragraphs = text.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) + 2 <= CHUNK_SIZE:
            current_chunk += para + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
                # –î–æ–±–∞–≤–ª—è–µ–º overlap: –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ CHUNK_OVERLAP —Å–∏–º–≤–æ–ª–æ–≤
                overlap_text = current_chunk[-CHUNK_OVERLAP:] if len(current_chunk) > CHUNK_OVERLAP else current_chunk
                current_chunk = overlap_text + "\n\n" + para + "\n\n"
            else:
                current_chunk = para + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


def analyze_document_with_deepseek(full_text: str, filename: str) -> dict:
    openrouter_key = os.environ.get('OPENROUTER_API_KEY', '')
    
    if not openrouter_key or not full_text or len(full_text) < 10:
        return {'summary': '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω', 'subject': '–û–±—â–µ–µ', 'title': filename[:50], 'tasks': []}
    
    print(f"[MATERIALS] OpenRouter/Llama –∞–Ω–∞–ª–∏–∑ –Ω–∞—á–∞—Ç, –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞={len(full_text)}")
    
    try:
        client = OpenAI(api_key=openrouter_key, base_url="https://api.aitunnel.ru/v1/", timeout=22.0)
        # –ë–µ—Ä—ë–º –±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–∞—á–∞–ª–æ + —Å–µ—Ä–µ–¥–∏–Ω–∞ + –∫–æ–Ω–µ—Ü)
        text_start = full_text[:2500]
        text_middle = full_text[len(full_text)//2:len(full_text)//2+2500] if len(full_text) > 5000 else ""
        text_end = full_text[-1000:] if len(full_text) > 3500 else ""
        text_preview = f"{text_start}\n\n[...—Å–µ—Ä–µ–¥–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...]\n{text_middle}\n\n[...–∫–æ–Ω–µ—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞...]\n{text_end}"
        
        prompt = f"""–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ —Å—Ç—É–¥–µ–Ω—Ç–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —É—á–µ–±–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç "{filename}".

–§—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞:
{text_preview}

–í–µ—Ä–Ω–∏ JSON:
{{"summary": "–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏)", "subject": "–ü—Ä–µ–¥–º–µ—Ç", "title": "–ù–∞–∑–≤–∞–Ω–∏–µ (–º–∞–∫—Å 50 —Å–∏–º–≤–æ–ª–æ–≤)", "tasks": [{{"title": "–ó–∞–¥–∞—á–∞", "deadline": "YYYY-MM-DD –∏–ª–∏ null"}}]}}"""
        
        response = client.chat.completions.create(
            model="deepseek-r1",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            response_format={"type": "json_object"})
        
        content = response.choices[0].message.content
        if '```json' in content:
            content = content.split('```json')[1].split('```')[0].strip()
        elif '```' in content:
            content = content.split('```')[1].split('```')[0].strip()
        
        result = json.loads(content)
        print(f"[MATERIALS] OpenRouter/Llama –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: title={result.get('title')}, subject={result.get('subject')}")
        return result
    except Exception as e:
        print(f"[MATERIALS] Artemox –æ—à–∏–±–∫–∞: {e}")
        return {'summary': '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω (–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)', 'subject': '–û–±—â–µ–µ', 'title': filename[:50], 'tasks': []}


def generate_share_code(material_id: int, user_id: int) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è —à–∞—Ä–∏–Ω–≥–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞"""
    return hashlib.md5(f"{material_id}:{user_id}".encode()).hexdigest()[:8].upper()


def handle_get_shared(code: str, headers: dict) -> dict:
    """–ü—É–±–ª–∏—á–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç: –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∞—Ä–µ–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –ø–æ –∫–æ–¥—É"""
    if not code or len(code) != 8:
        return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ–≤–µ—Ä–Ω—ã–π –∫–æ–¥'}, ensure_ascii=False)}

    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("SELECT id, user_id, title, subject, summary, recognized_text FROM materials ORDER BY id")
            for row in cur:
                expected = generate_share_code(row['id'], row['user_id'])
                if expected == code.upper():
                    text = row['recognized_text'] or ''
                    return {
                        'statusCode': 200,
                        'headers': headers,
                        'body': json.dumps({
                            'title': row['title'],
                            'subject': row['subject'],
                            'summary': row['summary'],
                            'recognized_text': text[:5000]
                        }, ensure_ascii=False, default=str)
                    }

        return {'statusCode': 404, 'headers': headers, 'body': json.dumps({'error': '–ú–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}, ensure_ascii=False)}
    finally:
        conn.close()


def handler(event: dict, context) -> dict:
    method = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {'statusCode': 200, 'headers': {'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'GET, POST, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Content-Type, Authorization, X-Authorization'}, 'body': ''}
    
    headers = {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'}
    
    # –ü—É–±–ª–∏—á–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç: –ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–∞—Å—à–∞—Ä–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)
    params = event.get('queryStringParameters') or {}
    if method == 'GET' and params.get('action') == 'shared':
        return handle_get_shared(params.get('code', ''), headers)
    
    auth_header = event.get('headers', {}).get('X-Authorization', '')
    token = auth_header.replace('Bearer ', '')
    
    if not token:
        return {'statusCode': 401, 'headers': headers, 'body': json.dumps({'error': '–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è'})}
    
    payload = verify_token(token)
    if not payload:
        return {'statusCode': 401, 'headers': headers, 'body': json.dumps({'error': '–ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω'})}
    
    user_id = payload['user_id']
    
    # POST - –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
    if method == 'POST':
        body = json.loads(event.get('body', '{}'))
        action = body.get('action')
        
        # –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ base64 (–æ–±—Ö–æ–¥ CORS –ø—Ä–æ–±–ª–µ–º)
        if action == 'upload_direct':
            try:
                conn = get_db_connection()
                access = check_subscription_access(conn, user_id)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –¥–ª—è Free –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (3 –º–∞—Ç–µ—Ä–∏–∞–ª–∞/–º–µ—Å—è—Ü)
                if not access['has_access']:
                    message = '‚è∞ –ü–æ–¥–ø–∏—Å–∫–∞ –∏—Å—Ç–µ–∫–ª–∞' if access.get('reason') == 'subscription_expired' else 'üîí –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–ø–∏—Å–∫–∞'
                    conn.close()
                    return {'statusCode': 403, 'headers': headers, 'body': json.dumps({'error': 'subscription_required', 'message': message})}
                
                # –î–ª—è Free –ø—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Å—è—á–Ω—ã–π –ª–∏–º–∏—Ç (2 –º–∞—Ç–µ—Ä–∏–∞–ª–∞)
                if not access.get('is_premium') and not access.get('is_trial'):
                    schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        cur.execute(f'''
                            SELECT materials_quota_used, materials_quota_reset_at 
                            FROM {schema}.users 
                            WHERE id = %s
                        ''', (user_id,))
                        quota_info = cur.fetchone()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏—Å—Ç–µ–∫ –ª–∏ –º–µ—Å—è—á–Ω—ã–π –ª–∏–º–∏—Ç
                        quota_used = quota_info.get('materials_quota_used', 0)
                        if quota_used >= 2:
                            conn.close()
                            return {'statusCode': 403, 'headers': headers, 'body': json.dumps({'error': 'quota_exceeded', 'message': 'üìä –õ–∏–º–∏—Ç –∑–∞–≥—Ä—É–∑–æ–∫ –∏—Å—á–µ—Ä–ø–∞–Ω (2/2). –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ Premium –¥–ª—è –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'})}
                
                conn.close()
                
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_data_base64 = body.get('fileData')
                
                if not filename or not file_type or not file_data_base64:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã filename, fileType –∏–ª–∏ fileData'})}
                
                import base64
                file_data = base64.b64decode(file_data_base64)
                file_size = len(file_data)
                
                if file_size > MAX_FILE_SIZE:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': f'–ú–∞–∫—Å —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // 1024 // 1024} –ú–ë'})}
                
                print(f"[MATERIALS] –ó–∞–≥—Ä—É–∑–∫–∞ {filename}, —Ä–∞–∑–º–µ—Ä={file_size} –±–∞–π—Ç")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
                s3 = get_s3_client()
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                import random
                file_key = f"materials/{user_id}_{timestamp}_{random.randint(10000000, 99999999)}_{filename}"
                
                s3.put_object(Bucket='files', Key=file_key, Body=file_data, ContentType=file_type)
                cdn_url = f"https://cdn.poehali.dev/projects/{os.environ['AWS_ACCESS_KEY_ID']}/bucket/{file_key}"
                
                print(f"[MATERIALS] –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ S3: {file_key}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
                print(f"[MATERIALS] –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç, —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
                full_text = extract_text_from_file(file_data, file_type)
                
                if not full_text or len(full_text.strip()) < 10:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                chunks = split_text_into_chunks(full_text)
                print(f"[MATERIALS] –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")
                
                analysis = analyze_document_with_deepseek(full_text, filename)
                print(f"[MATERIALS] DeepSeek —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {analysis}")
                
                title = (analysis.get('title') or filename)[:200]
                subject = (analysis.get('subject') or '–û–±—â–µ–µ')[:100]
                summary = (analysis.get('summary') or '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω')[:2000]
                file_type_short = file_type[:50]
                
                print(f"[MATERIALS] –î–∞–Ω–Ω—ã–µ: title={title[:50]}..., subject={subject}, len(summary)={len(summary)}, file_type={file_type_short}")
                
                conn = get_db_connection()
                print(f"[MATERIALS] –ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ OK")
                try:
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        print(f"[MATERIALS] –ù–∞—á–∏–Ω–∞—é INSERT materials –¥–ª—è user_id={user_id}...")
                        # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏, –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö - –≤–µ—Å—å —Ç–µ–∫—Å—Ç
                        text_preview = full_text[:2000] if len(chunks) > 1 else full_text[:10000]
                        cur.execute("""
                            INSERT INTO materials (user_id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            RETURNING id, title, subject, file_url, summary, file_type, file_size, total_chunks, created_at
                        """, (user_id, title, subject, cdn_url, text_preview, summary, file_type_short, file_size, len(chunks)))
                        print(f"[MATERIALS] INSERT materials OK")
                        
                        material = cur.fetchone()
                        material_id = material['id']
                        print(f"[MATERIALS] –ü–æ–ª—É—á–µ–Ω material_id={material_id}")
                        
                        for idx, chunk in enumerate(chunks):
                            cur.execute("INSERT INTO document_chunks (material_id, chunk_index, chunk_text) VALUES (%s, %s, %s)", (material_id, idx, chunk))
                        print(f"[MATERIALS] –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")
                        
                        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è Free
                        schema = os.environ.get('MAIN_DB_SCHEMA', 'public')
                        cur.execute(f'''
                            UPDATE {schema}.users 
                            SET materials_quota_used = materials_quota_used + 1
                            WHERE id = %s AND subscription_type = 'free'
                        ''', (user_id,))
                        
                        conn.commit()
                        print(f"[MATERIALS] COMMIT OK, –º–∞—Ç–µ—Ä–∏–∞–ª ID={material_id} —Å–æ–∑–¥–∞–Ω, –∫–≤–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
                        
                        return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'material': dict(material), 'chunks_created': len(chunks)}, default=str)}
                except Exception as db_error:
                    print(f"[MATERIALS] ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ë–î: {type(db_error).__name__}: {db_error}")
                    import traceback
                    traceback.print_exc()
                    raise
                finally:
                    conn.close()
            except Exception as e:
                print(f"[MATERIALS] ‚ùå –û—à–∏–±–∫–∞ upload_direct: {type(e).__name__}: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        # –®–∞–≥ 1: –ø–æ–ª—É—á–∏—Ç—å presigned URL (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥, –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        elif action == 'get_upload_url':
            try:
                conn = get_db_connection()
                access = check_subscription_access(conn, user_id)
                conn.close()
                
                if not access['has_access']:
                    message = '‚è∞ –ü–æ–¥–ø–∏—Å–∫–∞ –∏—Å—Ç–µ–∫–ª–∞' if access.get('reason') == 'subscription_expired' else 'üîí –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–ø–∏—Å–∫–∞'
                    return {'statusCode': 403, 'headers': headers, 'body': json.dumps({'error': 'subscription_required', 'message': message})}
                
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_size = body.get('fileSize', 0)
                
                if not filename or not file_type:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã filename –∏ fileType'})}
                
                if file_size > MAX_FILE_SIZE:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': f'–ú–∞–∫—Å —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // 1024 // 1024} –ú–ë'})}
                
                presigned_data = generate_presigned_upload_url(filename, file_type, user_id)
                if not presigned_data:
                    return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': '–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ URL'})}
                
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps(presigned_data)}
            except Exception as e:
                print(f"[MATERIALS] –û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        # –®–∞–≥ 2: –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        elif action == 'process_file':
            try:
                file_key = body.get('fileKey')
                cdn_url = body.get('cdnUrl')
                filename = body.get('filename')
                file_type = body.get('fileType')
                file_size = body.get('fileSize')
                
                if not file_key or not cdn_url:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω—ã fileKey/cdnUrl'})}
                
                print(f"[MATERIALS] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}, key={file_key}")
                file_data = download_file_from_s3(file_key)
                
                if not file_data:
                    return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç, —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
                full_text = extract_text_from_file(file_data, file_type)
                
                if not full_text or len(full_text.strip()) < 10:
                    return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞'})}
                
                print(f"[MATERIALS] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                chunks = split_text_into_chunks(full_text)
                analysis = analyze_document_with_deepseek(full_text, filename)
                
                title = (analysis.get('title') or filename)[:200]
                subject = (analysis.get('subject') or '–û–±—â–µ–µ')[:100]
                summary = (analysis.get('summary') or '–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω')[:2000]
                file_type_short = file_type[:50]
                
                conn = get_db_connection()
                try:
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏, –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö - –≤–µ—Å—å —Ç–µ–∫—Å—Ç
                        text_preview = full_text[:2000] if len(chunks) > 1 else full_text[:10000]
                        cur.execute("""
                            INSERT INTO materials (user_id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            RETURNING id, title, subject, file_url, summary, file_type, file_size, total_chunks, created_at
                        """, (user_id, title, subject, cdn_url, text_preview, summary, file_type_short, file_size, len(chunks)))
                        
                        material = cur.fetchone()
                        material_id = material['id']
                        
                        for idx, chunk in enumerate(chunks):
                            cur.execute("INSERT INTO document_chunks (material_id, chunk_index, chunk_text) VALUES (%s, %s, %s)", (material_id, idx, chunk))
                        
                        conn.commit()
                        print(f"[MATERIALS] –°–æ–∑–¥–∞–Ω: ID={material_id}")
                        return {'statusCode': 201, 'headers': headers, 'body': json.dumps({'material': dict(material), 'tasks': analysis.get('tasks', []), 'chunks_count': len(chunks)}, default=str)}
                finally:
                    conn.close()
            except Exception as e:
                print(f"[MATERIALS] –û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                return {'statusCode': 500, 'headers': headers, 'body': json.dumps({'error': str(e)})}
        
        elif action == 'share':
            material_id = body.get('material_id')
            if not material_id:
                return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ —É–∫–∞–∑–∞–Ω material_id'})}
            
            conn = get_db_connection()
            try:
                with conn.cursor() as cur:
                    cur.execute("SELECT id FROM materials WHERE id = %s AND user_id = %s", (material_id, user_id))
                    if not cur.fetchone():
                        return {'statusCode': 404, 'headers': headers, 'body': json.dumps({'error': '–ú–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'})}
                
                code = generate_share_code(int(material_id), user_id)
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'code': code, 'material_id': material_id}, ensure_ascii=False)}
            finally:
                conn.close()
        
        return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ'})}
    
    # GET - —Å–ø–∏—Å–æ–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
    elif method == 'GET':
        conn = get_db_connection()
        try:
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                cur.execute("SELECT id, title, subject, file_url, recognized_text, summary, file_type, file_size, total_chunks, created_at FROM materials WHERE user_id = %s ORDER BY created_at DESC", (user_id,))
                materials = cur.fetchall()
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'materials': [dict(m) for m in materials]}, default=str)}
        finally:
            conn.close()
    
    # DELETE - —É–¥–∞–ª–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª
    elif method == 'DELETE':
        material_id = event.get('queryStringParameters', {}).get('id')
        if not material_id:
            return {'statusCode': 400, 'headers': headers, 'body': json.dumps({'error': 'ID –Ω–µ —É–∫–∞–∑–∞–Ω'})}
        
        conn = get_db_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("DELETE FROM document_chunks WHERE material_id IN (SELECT id FROM materials WHERE id = %s AND user_id = %s)", (material_id, user_id))
                cur.execute("DELETE FROM materials WHERE id = %s AND user_id = %s", (material_id, user_id))
                conn.commit()
                
                if cur.rowcount == 0:
                    return {'statusCode': 404, 'headers': headers, 'body': json.dumps({'error': '–ù–µ –Ω–∞–π–¥–µ–Ω'})}
                
                return {'statusCode': 200, 'headers': headers, 'body': json.dumps({'message': '–£–¥–∞–ª—ë–Ω'})}
        finally:
            conn.close()
    
    return {'statusCode': 405, 'headers': headers, 'body': json.dumps({'error': '–ú–µ—Ç–æ–¥ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è'})}